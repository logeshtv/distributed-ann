# Trading ML System - Complete Codebase Analysis

## ğŸ“‹ Overview
This is an **aggressive ML trading system** targeting 100%+ annual returns using a hybrid **xLSTM-Transformer** architecture trained on US equities and cryptocurrency data.

---

## ğŸ”„ DATA DOWNLOAD FLOW

### Entry Point: `scripts/download_data.py`

#### 1. **Data Sources**
- **US Stocks**: Alpaca API (primary) â†’ fallback to yfinance (free)
- **Crypto**: Binance API only
- **Historical Range**: 2000-present (customizable)

#### 2. **Download Process**
```
download_data.py
â”œâ”€â”€ parse arguments (source, start_date, end_date, universe_size)
â”œâ”€â”€ load symbol lists from data/tickers.py
â”‚   â””â”€â”€ Small: 7 stocks + 3 crypto
â”‚   â””â”€â”€ Medium: 50 stocks + 10 crypto  
â”‚   â””â”€â”€ Large: 300+ stocks + 50+ crypto
â”œâ”€â”€ Call download_alpaca_data() or download_binance_data()
â””â”€â”€ Save to parquet files
    â”œâ”€â”€ data_storage/raw/stocks/
    â”œâ”€â”€ data_storage/raw/crypto/
```

#### 3. **Data Format** (after download)
- OHLCV data (Open, High, Low, Close, Volume)
- Columns: `timestamp`, `symbol`, `open`, `high`, `low`, `close`, `volume`, `vwap`
- Stored as `.parquet` files (efficient columnar format)

#### 4. **Command Examples**
```bash
# Download all data (small universe, last 5 years)
python scripts/download_data.py --source all --start 2019-01-01

# Download only stocks
python scripts/download_data.py --source alpaca --timeframe 1Day

# Download crypto only
python scripts/download_data.py --source binance --interval 1d
```

---

## ğŸ§  MODEL TRAINING FLOW

### Entry Point: `scripts/train_model.py`

#### 1. **Data Preparation Pipeline** (`data/pipeline.py` + `data/dataset.py`)

```
Raw Parquet Data
    â†“
DataPipeline.load_and_process()
    â”œâ”€â”€ Load all symbols from data_storage/raw/
    â”œâ”€â”€ Filter by date range
    â””â”€â”€ Sort by symbol + timestamp
    â†“
FeatureEngineer.add_all_features()
    â”œâ”€â”€ Return features (5, 10, 20 period returns)
    â”œâ”€â”€ Trend indicators (SMA, EMA, MACD, ADX, Aroon)
    â”œâ”€â”€ Momentum (RSI, Stochastic, Williams%R, ROC)
    â”œâ”€â”€ Volatility (ATR, Bollinger Bands, Keltner)
    â”œâ”€â”€ Volume (OBV, VWAP, CMF, Force Index)
    â””â”€â”€ Temporal (day of week, month - cyclical encoding)
    â†“
Total Features Generated: 60 features per timestamp
    â†“
Label Creation
    â”œâ”€â”€ target_return_1d (1-day % return)
    â”œâ”€â”€ target_return_4d (4-day % return)
    â”œâ”€â”€ target_return_24d (24-day % return)
    â”œâ”€â”€ target_direction (0=down, 1=neutral, 2=up)
    â””â”€â”€ Threshold: Â±0.5% for classification
    â†“
Train/Val/Test Split
    â”œâ”€â”€ 70% training
    â”œâ”€â”€ 15% validation
    â””â”€â”€ 15% testing
```

#### 2. **TradingDataset** (`data/dataset.py`)
- Creates sequences: **60 timesteps Ã— 60 features = (batch_size, 60, 60)**
- Sliding window approach with no lookahead bias
- Returns: `{'features': Tensor, 'targets': Tensor}`

#### 3. **Model Architecture** (`models/trading_nn.py`)

```
INPUT LAYER (60 features, 60 timesteps)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         DUAL-PATH ENCODING                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚
â”œâ”€â†’ PATH A: xLSTM ENCODER
â”‚   â”œâ”€â”€ 3 layers
â”‚   â”œâ”€â”€ 512 hidden units
â”‚   â”œâ”€â”€ Exponential gating (prevents gradient explosion)
â”‚   â””â”€â”€ Output: 512 dimensions
â”‚
â”œâ”€â†’ PATH B: TRANSFORMER ENCODER
â”‚   â”œâ”€â”€ 3 layers
â”‚   â”œâ”€â”€ 8 attention heads
â”‚   â”œâ”€â”€ 256 embedding dimension
â”‚   â”œâ”€â”€ Self-attention (pattern recognition)
â”‚   â””â”€â”€ Output: 256 dimensions
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
FUSION LAYER
â”œâ”€â”€ Concatenate xLSTM (512) + Transformer (256)
â”œâ”€â”€ Attention mechanism to weight contributions
â””â”€â”€ Output: 256 dimensions
    â†“
POSITION STATE ENCODER (optional)
â”œâ”€â”€ Embeds current portfolio state
â”œâ”€â”€ Embedding dimension: 320
â”œâ”€â”€ Integrates with market features
â””â”€â”€ Output: 256 dimensions (after integration)
    â†“
TEMPORAL FUSION
â”œâ”€â”€ Aggregates sequence to vector
â””â”€â”€ Output: 256 dimensions
    â†“
MULTI-TASK OUTPUT HEADS
â”œâ”€â”€ 1. Price Prediction (3 outputs: 1d, 4d, 24d returns)
â”œâ”€â”€ 2. Direction Classification (3 classes: up/neutral/down)
â”œâ”€â”€ 3. Position Sizing (3 classes: buy/hold/sell)
â”œâ”€â”€ 4. Volatility Forecast (regression)
â”œâ”€â”€ 5. Confidence Score (0-1)
â””â”€â”€ 6. Risk Signal (0-1)
```

**Model Parameters**: ~27.1 million

#### 4. **Training Loop** (`training/trainer.py`)

```
Trainer() class
â”œâ”€â”€ Optimizer: AdamW (learning_rate=5e-4, weight_decay=1e-5)
â”œâ”€â”€ Scheduler: CosineAnnealingWarmRestarts (T_0=10, T_mult=2)
â”œâ”€â”€ Loss Function: MultiTaskLoss (weighted)
â”‚   â”œâ”€â”€ Price loss: 0.30 weight
â”‚   â”œâ”€â”€ Direction loss: 0.20 weight
â”‚   â”œâ”€â”€ Volatility loss: 0.15 weight
â”‚   â”œâ”€â”€ Position loss: 0.20 weight
â”‚   â”œâ”€â”€ Risk loss: 0.10 weight
â”‚   â””â”€â”€ Confidence loss: 0.05 weight
â”‚
â”œâ”€â”€ Gradient Accumulation: supports for large batch sizes
â”œâ”€â”€ Gradient Clipping: max_norm=1.0
â”œâ”€â”€ Early Stopping: patience=15 epochs
â””â”€â”€ Checkpointing: best_model.pt saved when val_loss improves
```

#### 5. **Training Command**
```bash
python scripts/train_model.py \
    --data-path data_storage/raw \
    --epochs 100 \
    --batch-size 64 \
    --lr 0.0005 \
    --device cuda
```

#### 6. **Output**
- Trained model saved to: `data_storage/models/best_model.pt`
- Training logs to: `logs/`
- Validation metrics tracked per epoch

---

## ğŸ¯ EXECUTION & BACKTESTING

### Backtesting: `scripts/backtest.py` â†’ `execution/backtester.py`

```
Historical Data (OHLCV)
    â†“
Backtester.run()
    â”œâ”€â”€ Load trained model
    â”œâ”€â”€ For each timestamp:
    â”‚   â”œâ”€â”€ Get latest 60 bars
    â”‚   â”œâ”€â”€ Extract features
    â”‚   â”œâ”€â”€ Pass through model â†’ get predictions
    â”‚   â”œâ”€â”€ Generate trading signal (direction output)
    â”‚   â”œâ”€â”€ Check risk limits (RiskManager)
    â”‚   â”œâ”€â”€ Execute position (PositionTracker)
    â”‚   â”œâ”€â”€ Apply slippage (10 bps default)
    â”‚   â”œâ”€â”€ Apply commission (0.1% default)
    â”‚   â””â”€â”€ Record equity curve
    â”‚
    â””â”€â”€ Generate BacktestResult
        â”œâ”€â”€ Total return
        â”œâ”€â”€ Sharpe ratio
        â”œâ”€â”€ Max drawdown
        â”œâ”€â”€ Win rate
        â”œâ”€â”€ Profit factor
        â””â”€â”€ Trades list
```

### Risk Management: `execution/risk_manager.py`
- Max position size: configurable
- Max daily loss: stop-loss trigger
- Correlation checks: prevent over-concentration
- Leverage limits: drawdown protection

### Paper Trading: `scripts/paper_trade.py`
- Real-time trading without capital risk
- Connects to Alpaca/Binance APIs
- Records signals for later analysis

---

## ğŸŒ FRONTEND (CURRENT)

### Web Stack
- **Backend**: FastAPI (Python)
- **Frontend**: HTML/CSS/JavaScript
- **WebSocket**: Real-time training updates
- **Port**: 8000

### Files
- `web/app.py` - FastAPI endpoints
- `web/static/index.html` - UI (HTML)
- `web/static/app.js` - UI logic (JavaScript)
- `web/static/styles.css` - Styling
- `web/training_service.py` - Background training tasks

### Current Frontend Features
1. **Data Download Manager**
   - Source selection (stocks/crypto/all)
   - Universe size (small/medium/large)
   - Date range picker
   - Progress tracking

2. **Training Configuration**
   - Epochs, batch size, learning rate
   - Sequence length, patience
   - Data path specification

3. **Training Monitor**
   - Real-time loss curves
   - Progress bar
   - Logs streaming

4. **Model Management**
   - List trained models
   - Download/delete models
   - View model info

### API Endpoints
- `POST /api/download-data` - Start data download
- `GET /api/download-status` - Check download progress
- `POST /api/train` - Start training
- `GET /api/training-status` - Training progress
- `WS /ws` - WebSocket for real-time updates
- `GET /api/models` - List models
- `POST /api/backtest` - Run backtest

---

## ğŸ—ï¸ ARCHITECTURE INSIGHTS

### Strengths âœ…
1. **Dual-path architecture** captures both temporal dependencies (xLSTM) and patterns (Transformer)
2. **Feature-rich**: 60+ technical indicators provide comprehensive market context
3. **Multi-task learning**: Predicts price, direction, volatility, confidence simultaneously
4. **Position state integration**: Model aware of current holdings
5. **Robust backtesting**: Realistic slippage, commission, risk management
6. **Web interface**: Easy to configure & monitor training

### Limitations/Concerns âš ï¸
1. **60 features â†’ may be redundant** (correlation between indicators)
2. **3-layer xLSTM + 3-layer Transformer** = Deep model, risk of overfitting
3. **27.1M parameters** on potentially limited data â†’ needs regularization
4. **Frontend is basic** - no portfolio monitoring, no live trading view
5. **Index data not supported** - only individual symbols (SPY, QQQ, individual stocks)
6. **No support for index futures** or spread trading

---

## ğŸ“Š PROPOSED ARCHITECTURE IMPROVEMENTS

### 1. **Feature Reduction**
- Current: 60 features
- Proposed: 25-30 key features (PCA or correlation filtering)
- Benefits: Faster training, less overfitting, interpretability

### 2. **Model Simplification Option A**
```
Input â†’ xLSTM (2 layers) â†’ Temporal Pooling â†’ Output Heads
(Simpler, faster training)
```

### 3. **Model Simplification Option B** (Ensemble approach)
```
Input â†’ Separate models per task:
  â”œâ”€ Direction predictor (2-layer xLSTM)
  â”œâ”€ Price predictor (Transformer only)
  â””â”€ Risk predictor (Simpler network)
(More interpretable, easier to debug)
```

### 4. **Index Data Support**
- Add index calculation module
- Support OHLCV reconstructed from constituents
- Track index momentum separately

### 5. **New Frontend (React-based)**
- Real-time portfolio dashboard
- Live P&L tracking
- Trade notifications
- Model performance metrics
- Data quality indicators

### 6. **Advanced Training Features**
- Meta-learning for quick adaptation to new markets
- Online learning for live retraining
- Attention visualization for interpretability

---

## ğŸ“ KEY FILES SUMMARY

| File | Purpose |
|------|---------|
| `scripts/download_data.py` | Download historical data |
| `scripts/train_model.py` | Train the model |
| `scripts/backtest.py` | Backtest trained model |
| `scripts/paper_trade.py` | Paper trading |
| `data/features.py` | Feature engineering (60+ indicators) |
| `data/pipeline.py` | Data processing pipeline |
| `models/trading_nn.py` | Main neural network |
| `models/xlstm.py` | xLSTM implementation |
| `models/transformer.py` | Transformer encoder |
| `training/trainer.py` | Training loop |
| `execution/backtester.py` | Backtesting engine |
| `execution/risk_manager.py` | Risk management |
| `web/app.py` | FastAPI application |
| `config/model_config.py` | Model hyperparameters |
| `config/settings.py` | Global settings |

---

## ğŸš€ NEXT STEPS FOR REDESIGN

1. **Phase 1**: Understand current results (backtest performance)
2. **Phase 2**: Reduce features to 25-30 key indicators
3. **Phase 3**: Add index data support (SPY, QQQ, sector ETFs)
4. **Phase 4**: Redesign frontend (React-based or Vue.js)
5. **Phase 5**: Implement new frontend backend API
6. **Phase 6**: Support index futures and spread trading
7. **Phase 7**: Add ensemble methods or model selection logic

