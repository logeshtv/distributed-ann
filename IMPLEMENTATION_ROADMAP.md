# ğŸ—ºï¸ DETAILED ACTION PLAN: Data, Training & Frontend Rebuild

## Part 1: DATA PIPELINE - Comprehensive View

### Current Data Flow Diagram
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  DATA SOURCES                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“                      â†“                      â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ALPACA  â”‚          â”‚ BINANCE  â”‚          â”‚ yfinance â”‚
    â”‚(Stocks)  â”‚          â”‚ (Crypto) â”‚          â”‚(Fallback)â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“                      â†“                      â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚        download_data.py (Entry Point)            â”‚
    â”‚  - Parse args (source, dates, universe_size)    â”‚
    â”‚  - Load symbol lists from data/tickers.py       â”‚
    â”‚  - Call fetch functions                         â”‚
    â”‚  - Handle errors, retry logic                   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  DATA FORMAT: Raw OHLCV Parquet Files            â”‚
    â”‚  Location: data_storage/raw/{stocks,crypto}/     â”‚
    â”‚  Columns: timestamp, symbol, open, high,        â”‚
    â”‚           low, close, volume, vwap              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  IMPROVEMENT #1: Add Index Data                  â”‚
    â”‚  â”œâ”€ S&P 500 (SPY)                               â”‚
    â”‚  â”œâ”€ NASDAQ 100 (QQQ)                            â”‚
    â”‚  â”œâ”€ Russell 2000 (IWM)                          â”‚
    â”‚  â”œâ”€ Sector ETFs (XLK, XLF, XLV, etc.)          â”‚
    â”‚  â””â”€ Volatility Index (VIX)                      â”‚
    â”‚  Location: data_storage/raw/indices/            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  train_model.py â†’ DataPipeline                   â”‚
    â”‚  - Load all parquet files                       â”‚
    â”‚  - Sort by symbol + timestamp                   â”‚
    â”‚  - Filter by date range                         â”‚
    â”‚  - Handle missing data                          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  IMPROVEMENT #2: Feature Selection               â”‚
    â”‚  Current: 60 features â†’ Target: 35-40 features  â”‚
    â”‚  Methods:                                        â”‚
    â”‚  â”œâ”€ Correlation filtering (|r| > 0.8)           â”‚
    â”‚  â”œâ”€ Feature importance (XGBoost ranking)        â”‚
    â”‚  â”œâ”€ PCA (25-30 components)                      â”‚
    â”‚  â””â”€ Domain knowledge (keep proven indicators)   â”‚
    â”‚  Output: features_selected_df.parquet           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  FeatureEngineer.add_all_features()              â”‚
    â”‚  â”œâ”€ Return features (5,10,20 period)            â”‚
    â”‚  â”œâ”€ Trend: SMA, EMA, MACD, ADX, Aroon          â”‚
    â”‚  â”œâ”€ Momentum: RSI, Stochastic, Williams%R      â”‚
    â”‚  â”œâ”€ Volatility: ATR, Bollinger Bands           â”‚
    â”‚  â”œâ”€ Volume: OBV, VWAP, CMF                     â”‚
    â”‚  â”œâ”€ Temporal: day_of_week, month               â”‚
    â”‚  â””â”€ Index relatives (NEW)                       â”‚
    â”‚     â”œâ”€ Correlation to index                     â”‚
    â”‚     â”œâ”€ Beta calculation                         â”‚
    â”‚     â””â”€ Relative strength vs index               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Label Creation (per symbol)                     â”‚
    â”‚  For each timestamp:                             â”‚
    â”‚  â”œâ”€ target_return_1d = (close[t+1]/close[t])-1  â”‚
    â”‚  â”œâ”€ target_return_4d = (close[t+4]/close[t])-1  â”‚
    â”‚  â”œâ”€ target_return_24d = (close[t+24]/close[t])-1â”‚
    â”‚  â”œâ”€ target_direction = classify by Â±0.5%        â”‚
    â”‚  â”œâ”€ target_volatility = future ATR              â”‚
    â”‚  â””â”€ target_confidence = model certainty (0-1)   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Train/Val/Test Split                            â”‚
    â”‚  â”œâ”€ 70% Training (2000-2022)                    â”‚
    â”‚  â”œâ”€ 15% Validation (2022-2023)                  â”‚
    â”‚  â””â”€ 15% Testing (2023-2024)                     â”‚
    â”‚  Note: Temporal split to avoid look-ahead bias  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  TradingDataset (PyTorch)                        â”‚
    â”‚  - Sequences: 60 timesteps Ã— 40 features        â”‚
    â”‚  - Batch: DataLoader(batch_size=512)            â”‚
    â”‚  - Returns: {features, targets}                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Implementation Tasks

#### Task 1.1: Add Index Data Source
```python
# data/fetchers/index_fetcher.py (NEW)

class IndexFetcher:
    """Fetch major indices and sector ETFs."""
    
    INDICES = {
        'SPY': 'S&P 500',
        'QQQ': 'NASDAQ 100',
        'IWM': 'Russell 2000',
        'VIX': 'Volatility Index'
    }
    
    SECTOR_ETFS = {
        'XLK': 'Technology',
        'XLF': 'Financials',
        'XLV': 'Healthcare',
        'XLI': 'Industrials',
        'XLP': 'Consumer Staples',
        'XLY': 'Consumer Discretionary',
        'XLRE': 'Real Estate',
        'XLE': 'Energy',
        'XLU': 'Utilities',
        'XLRE': 'Materials'
    }
    
    def fetch_indices(self, start_date, end_date):
        """Fetch all indices."""
        # Use yfinance for all (free, no API key)
        pass
```

#### Task 1.2: Feature Selection Module
```python
# data/feature_selector.py (NEW)

class FeatureSelector:
    """Select optimal features from 60 available."""
    
    def rank_by_correlation(self, df):
        """Remove highly correlated features."""
        # Keep 1 from each correlation group
        # Result: 60 â†’ 40 features
        pass
    
    def rank_by_importance(self, df, labels):
        """Train quick XGBoost, get importances."""
        # Quick model for feature ranking
        # Keep top 35 features
        pass
    
    def rank_by_pca(self, df, n_components=30):
        """PCA transformation."""
        # Reduce to 30 principal components
        pass
    
    def get_selected_features(self, method='correlation'):
        """Return list of selected feature columns."""
        pass
```

---

## Part 2: MODEL TRAINING - Architecture Comparison

### Training Data Flow with Three Model Variants

```
                     PREPARED DATA (70% train set)
                              â†“
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â†“                           â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ CONFIG MODEL â”‚            â”‚  INITIALIZE  â”‚
        â”‚ ARCHITECTURE â”‚            â”‚   TRAINER    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“                              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     THREE MODEL ARCHITECTURES          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“              â†“              â†“
    
OPTION A          OPTION B          OPTION C
SimplexLSTM       EfficientHybrid    TaskEnsemble
â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Input(40)         Input(40)          Input(40)
    â†“                 â†“                 â”œâ”€â†’ DirectionNet
xLSTM             xLSTM(256,2L)      â”‚   (xLSTM 2L)
(256,2L)          + Transformer      â”œâ”€â†’ PriceNet
    â†“             (128,2L)           â”‚   (Transformer 2L)
Pool              â†“                  â””â”€â†’ RiskNet
    â†“             Fusion             (MLP 2L)
Head            â†“                  â†“
                 Head            Ensemble
~3M params       ~6M params      ~8M params
Fast âš¡         Balanced        Interpretable

TRAINING (All Options):
â”œâ”€ Optimizer: AdamW (lr=5e-4)
â”œâ”€ Scheduler: CosineAnnealingWarmRestarts
â”œâ”€ Loss: MultiTaskLoss (weighted)
â”œâ”€ Batch size: 512
â”œâ”€ Epochs: 100
â”œâ”€ Early stopping: patience=15
â””â”€ Device: GPU (cuda)

PER EPOCH:
â”œâ”€ Forward pass on all batches
â”œâ”€ Backward pass (grad accumulation)
â”œâ”€ Update weights
â”œâ”€ Validation on val set (15%)
â”œâ”€ Log metrics
â””â”€ Save checkpoint if val_loss improves

OUTPUTS:
â”œâ”€ Best model saved: data_storage/models/
â”œâ”€ Training curves: loss vs epoch
â”œâ”€ Validation metrics: MAE, accuracy, AUC
â””â”€ Training logs: logs/
```

### Implementation: Model Architecture Variants

#### Task 2.1: SimplexLSTM (Fast Option)
```python
# models/variants/simplex_lstm.py

import torch.nn as nn

class SimplexLSTM(nn.Module):
    """Single-path xLSTM architecture."""
    
    def __init__(self, 
                 input_dim: int = 40,
                 hidden_dim: int = 256,
                 num_layers: int = 2,
                 output_dim: int = 256):
        super().__init__()
        self.xlstm = xLSTM(
            input_size=input_dim,
            hidden_size=hidden_dim,
            num_layers=num_layers,
            dropout=0.3
        )
        self.temporal_pool = TemporalFusion(hidden_dim, output_dim)
        self.heads = MultiTaskHead(output_dim)
    
    def forward(self, x):
        x = self.xlstm(x)  # (batch, seq, hidden)
        x = self.temporal_pool(x)  # (batch, output_dim)
        outputs = self.heads(x)
        return outputs

# Parameters: ~3M
# Training time: ~30-45 min on GPU
# Inference: ~15ms per sample
```

#### Task 2.2: EfficientHybrid (Balanced)
```python
# models/variants/efficient_hybrid.py

class EfficientHybrid(nn.Module):
    """Reduced-complexity hybrid architecture."""
    
    def __init__(self,
                 input_dim: int = 40,
                 xlstm_hidden: int = 256,
                 transformer_dim: int = 128,
                 output_dim: int = 256):
        super().__init__()
        self.xlstm = xLSTM(input_dim, xlstm_hidden, num_layers=2)
        self.transformer = TransformerEncoder(
            input_dim, 
            d_model=transformer_dim,
            nhead=4,  # Reduced from 8
            num_layers=2  # Reduced from 3
        )
        self.fusion = FusionLayer(
            xlstm_dim=xlstm_hidden,
            transformer_dim=transformer_dim,
            output_dim=output_dim
        )
        self.heads = MultiTaskHead(output_dim)
    
    def forward(self, x):
        xlstm_out = self.xlstm(x)
        transformer_out = self.transformer(x)
        fused = self.fusion(xlstm_out, transformer_out)
        outputs = self.heads(fused)
        return outputs

# Parameters: ~6M
# Training time: ~45-60 min
# Inference: ~20ms per sample
```

#### Task 2.3: TaskEnsemble (Interpretable)
```python
# models/variants/task_ensemble.py

class DirectionNet(nn.Module):
    """Predict direction only."""
    def __init__(self, input_dim=40):
        super().__init__()
        self.net = nn.Sequential(
            xLSTM(input_dim, 256, 2),
            TemporalFusion(256, 256),
            nn.Linear(256, 3)  # 3 classes: down/neutral/up
        )
    
    def forward(self, x):
        return self.net(x)

class PriceNet(nn.Module):
    """Predict future returns."""
    def __init__(self, input_dim=40):
        super().__init__()
        self.net = nn.Sequential(
            TransformerEncoder(input_dim, 128, 4, 2),
            TemporalFusion(128, 256),
            nn.Linear(256, 3)  # 1d, 4d, 24d returns
        )
    
    def forward(self, x):
        return self.net(x)

class RiskNet(nn.Module):
    """Predict volatility & confidence."""
    def __init__(self, input_dim=40):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim*60, 128),  # Flatten
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 2)  # volatility, confidence
        )
    
    def forward(self, x):
        x = x.view(x.size(0), -1)
        return self.net(x)

class TaskEnsemble(nn.Module):
    """Ensemble of task-specific models."""
    
    def __init__(self, input_dim=40):
        super().__init__()
        self.direction_net = DirectionNet(input_dim)
        self.price_net = PriceNet(input_dim)
        self.risk_net = RiskNet(input_dim)
    
    def forward(self, x):
        direction = self.direction_net(x)
        price = self.price_net(x)
        risk = self.risk_net(x)
        
        return {
            'direction': direction,
            'price': price,
            'risk': risk
        }

# Parameters: ~8M total
# Training time: ~50-70 min
# Inference: ~25ms per sample
```

### Training Script Comparison
```bash
# Compare all three architectures
python scripts/train_model.py \
    --data-path data_storage/raw \
    --model simplex_lstm \
    --epochs 100 \
    --output-dir results/model_comparison/simplex_lstm

python scripts/train_model.py \
    --data-path data_storage/raw \
    --model efficient_hybrid \
    --epochs 100 \
    --output-dir results/model_comparison/efficient_hybrid

python scripts/train_model.py \
    --data-path data_storage/raw \
    --model task_ensemble \
    --epochs 100 \
    --output-dir results/model_comparison/task_ensemble

# Compare results
python scripts/compare_models.py --results-dir results/model_comparison/
```

---

## Part 3: FRONTEND REDESIGN - Complete New Stack

### Current Frontend Issues
```
âŒ Single HTML file (260 lines)
âŒ No state management
âŒ No component reusability
âŒ Limited visualization
âŒ No portfolio tracking
âŒ No real-time updates
âŒ Hard to extend
```

### New Frontend Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              REACT APPLICATION (Frontend)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚
â”œâ”€ src/
â”‚  â”œâ”€ pages/
â”‚  â”‚  â”œâ”€ Dashboard.tsx        (Main portfolio view)
â”‚  â”‚  â”œâ”€ DataManager.tsx       (Download & preprocess)
â”‚  â”‚  â”œâ”€ Training.tsx          (Configuration & monitor)
â”‚  â”‚  â”œâ”€ Backtest.tsx          (Simulation & results)
â”‚  â”‚  â”œâ”€ LiveTrading.tsx       (Real-time signals)
â”‚  â”‚  â””â”€ Settings.tsx          (Configuration)
â”‚  â”‚
â”‚  â”œâ”€ components/
â”‚  â”‚  â”œâ”€ PortfolioCard.tsx     (Equity, drawdown, Sharpe)
â”‚  â”‚  â”œâ”€ SignalsList.tsx       (Recent signals)
â”‚  â”‚  â”œâ”€ TrainingMonitor.tsx   (Loss curves)
â”‚  â”‚  â”œâ”€ DataQualityCheck.tsx  (Data health)
â”‚  â”‚  â”œâ”€ RiskDashboard.tsx     (Risk metrics)
â”‚  â”‚  â””â”€ Charts/
â”‚  â”‚     â”œâ”€ EquityCurve.tsx
â”‚  â”‚     â”œâ”€ LossCurve.tsx
â”‚  â”‚     â”œâ”€ DrawdownChart.tsx
â”‚  â”‚     â””â”€ SignalHeatmap.tsx
â”‚  â”‚
â”‚  â”œâ”€ hooks/
â”‚  â”‚  â”œâ”€ useWebSocket.ts      (Real-time connection)
â”‚  â”‚  â”œâ”€ usePortfolio.ts      (Portfolio state)
â”‚  â”‚  â”œâ”€ useTraining.ts       (Training state)
â”‚  â”‚  â””â”€ useBacktest.ts       (Backtest results)
â”‚  â”‚
â”‚  â”œâ”€ services/
â”‚  â”‚  â”œâ”€ api.ts              (API calls)
â”‚  â”‚  â”œâ”€ websocket.ts        (WebSocket manager)
â”‚  â”‚  â””â”€ storage.ts          (Local storage)
â”‚  â”‚
â”‚  â”œâ”€ types/
â”‚  â”‚  â””â”€ index.ts            (TypeScript types)
â”‚  â”‚
â”‚  â””â”€ App.tsx               (Root component)
â”‚
â”œâ”€ public/
â”‚  â”œâ”€ index.html
â”‚  â”œâ”€ favicon.ico
â”‚  â””â”€ config.json
â”‚
â”œâ”€ package.json
â”œâ”€ tsconfig.json
â””â”€ .env.example
```

### New Frontend Stack

```
Frontend:
â”œâ”€ React 18 (UI framework)
â”œâ”€ TypeScript (type safety)
â”œâ”€ Recharts (data visualization)
â”œâ”€ Zustand (state management)
â”œâ”€ React Query (server state)
â”œâ”€ Tailwind CSS (styling)
â”œâ”€ Axios (HTTP client)
â””â”€ date-fns (date handling)

Backend API (FastAPI):
â”œâ”€ /api/v1/portfolio
â”‚  â”œâ”€ GET /current        â†’ Current positions & P&L
â”‚  â”œâ”€ GET /history        â†’ Historical trades
â”‚  â””â”€ GET /performance    â†’ Sharpe, max DD, returns
â”‚
â”œâ”€ /api/v1/signals
â”‚  â”œâ”€ GET /recent         â†’ Latest 20 signals
â”‚  â”œâ”€ GET /by-symbol/{s}  â†’ Signals for symbol
â”‚  â””â”€ GET /confidence     â†’ High confidence signals
â”‚
â”œâ”€ /api/v1/training
â”‚  â”œâ”€ GET /status         â†’ Current training status
â”‚  â”œâ”€ GET /metrics        â†’ Loss, accuracy curves
â”‚  â”œâ”€ POST /start         â†’ Start training
â”‚  â””â”€ POST /stop          â†’ Stop training
â”‚
â”œâ”€ /api/v1/backtest
â”‚  â”œâ”€ POST /run           â†’ Start backtest
â”‚  â”œâ”€ GET /results/{id}   â†’ Backtest results
â”‚  â””â”€ GET /trades/{id}    â†’ Trades list
â”‚
â”œâ”€ /api/v1/data
â”‚  â”œâ”€ POST /download      â†’ Start download
â”‚  â”œâ”€ GET /status         â†’ Download progress
â”‚  â””â”€ GET /quality        â†’ Data quality check
â”‚
â””â”€ /api/v1/system
   â”œâ”€ GET /health         â†’ System status
   â”œâ”€ GET /config         â†’ Current configuration
   â””â”€ GET /logs           â†’ Recent logs
```

### Frontend Component Examples

#### Dashboard Page
```typescript
// src/pages/Dashboard.tsx

import { usePortfolio } from '../hooks/usePortfolio';
import { useWebSocket } from '../hooks/useWebSocket';
import PortfolioCard from '../components/PortfolioCard';
import SignalsList from '../components/SignalsList';
import EquityCurve from '../components/Charts/EquityCurve';
import RiskDashboard from '../components/RiskDashboard';

export default function Dashboard() {
  const portfolio = usePortfolio();
  const signals = useWebSocket('/ws/signals');
  
  return (
    <div className="grid grid-cols-4 gap-4">
      <PortfolioCard
        equity={portfolio.equity}
        return={portfolio.totalReturn}
        sharpe={portfolio.sharpeRatio}
        maxDD={portfolio.maxDrawdown}
      />
      
      <EquityCurve data={portfolio.equityCurve} />
      
      <RiskDashboard
        positions={portfolio.positions}
        dailyLoss={portfolio.dailyLoss}
        var95={portfolio.var95}
      />
      
      <SignalsList signals={signals} />
    </div>
  );
}
```

#### Training Monitor Component
```typescript
// src/components/TrainingMonitor.tsx

import { useTraining } from '../hooks/useTraining';
import { LineChart, Line, XAxis, YAxis } from 'recharts';

export default function TrainingMonitor() {
  const training = useTraining();
  
  return (
    <div className="card">
      <h2>Training Progress</h2>
      
      <div className="grid grid-cols-2">
        <div>
          <p>Epoch: {training.epoch}/100</p>
          <p>Loss: {training.loss.toFixed(4)}</p>
          <p>Val Loss: {training.valLoss.toFixed(4)}</p>
        </div>
        
        <LineChart width={400} height={300} data={training.losses}>
          <XAxis dataKey="epoch" />
          <YAxis />
          <Line type="monotone" dataKey="loss" stroke="#8884d8" />
          <Line type="monotone" dataKey="valLoss" stroke="#82ca9d" />
        </LineChart>
      </div>
    </div>
  );
}
```

### Backend API Additions

```python
# web/app.py (Extended)

from fastapi import FastAPI, WebSocket, BackgroundTasks
from fastapi.responses import JSONResponse
import asyncio
from datetime import datetime

app = FastAPI()

# Portfolio endpoints
@app.get("/api/v1/portfolio/current")
async def get_portfolio():
    """Get current portfolio state."""
    return {
        "equity": position_tracker.equity,
        "cash": position_tracker.cash,
        "positions": position_tracker.positions,
        "totalReturn": (position_tracker.equity - INITIAL_CAPITAL) / INITIAL_CAPITAL,
        "timestamp": datetime.now().isoformat()
    }

@app.get("/api/v1/portfolio/performance")
async def get_performance():
    """Get performance metrics."""
    return {
        "sharpeRatio": calculate_sharpe(equity_curve),
        "sortinoRatio": calculate_sortino(equity_curve),
        "maxDrawdown": calculate_max_dd(equity_curve),
        "winRate": calculate_win_rate(trades),
        "profitFactor": calculate_profit_factor(trades)
    }

# Signal endpoints
@app.get("/api/v1/signals/recent")
async def get_recent_signals(limit: int = 20):
    """Get recent trading signals."""
    return signal_buffer[-limit:]

@app.get("/api/v1/signals/confidence")
async def get_high_confidence_signals(threshold: float = 0.7):
    """Get signals with confidence > threshold."""
    return [s for s in signal_buffer if s['confidence'] > threshold]

# Training endpoints
@app.post("/api/v1/training/start")
async def start_training(config: TrainingConfig, background_tasks: BackgroundTasks):
    """Start model training."""
    background_tasks.add_task(training_service.train, config)
    return {"status": "training_started"}

@app.get("/api/v1/training/status")
async def get_training_status():
    """Get current training status."""
    return training_service.get_status()

# WebSocket for real-time updates
@app.websocket("/ws/signals")
async def websocket_signals(websocket: WebSocket):
    """WebSocket endpoint for real-time signals."""
    await websocket.accept()
    try:
        while True:
            signal = signal_queue.get()  # Non-blocking queue
            await websocket.send_json(signal)
            await asyncio.sleep(0.1)
    except WebSocketDisconnect:
        pass
```

---

## Part 4: EXECUTION & IMPLEMENTATION TIMELINE

### Week 1-2: Foundation
```
Tasks:
â””â”€ [ ] Document current performance (backtest results)
â””â”€ [ ] Create baseline metrics file
â””â”€ [ ] Add index data fetching (SPY, QQQ, VIX)
â””â”€ [ ] Implement feature selection module
â””â”€ [ ] Run correlation analysis (60 â†’ 35 features)
```

### Week 3-4: Model Optimization
```
Tasks:
â””â”€ [ ] Implement SimplexLSTM variant
â””â”€ [ ] Implement EfficientHybrid variant
â””â”€ [ ] Implement TaskEnsemble variant
â””â”€ [ ] Compare all 3 architectures
â””â”€ [ ] Benchmark: speed, accuracy, generalization
â””â”€ [ ] Select best architecture
```

### Week 5-7: Frontend V1
```
Tasks:
â””â”€ [ ] Setup React project structure
â””â”€ [ ] Implement Dashboard page
â””â”€ [ ] Implement DataManager page
â””â”€ [ ] Implement Training page
â””â”€ [ ] Connect to backend APIs
â””â”€ [ ] Test all components
â””â”€ [ ] Deploy to localhost:3000
```

### Week 8-10: Advanced Features
```
Tasks:
â””â”€ [ ] Implement curriculum learning
â””â”€ [ ] Implement online learning
â””â”€ [ ] Add attention visualization
â””â”€ [ ] Add model ensembling
â””â”€ [ ] Implement walk-forward validation
â””â”€ [ ] Stress testing (market crashes)
```

### Week 11+: Production
```
Tasks:
â””â”€ [ ] Live trading pipeline
â””â”€ [ ] Monitoring & alerting
â””â”€ [ ] Cloud deployment (Railway/AWS)
â””â”€ [ ] Documentation
â””â”€ [ ] Performance monitoring
```

---

## ğŸ“ QUICK START COMMANDS

### Phase 1: Add Index Data
```bash
# Create new fetcher
touch data/fetchers/index_fetcher.py

# Update tickers.py
# Add: INDEX_SYMBOLS = ['SPY', 'QQQ', 'IWM', 'VIX']

# Update download_data.py
# Add: --include-indices flag

# Test
python scripts/download_data.py --source all --include-indices
```

### Phase 2: Feature Selection
```bash
# Create feature selector
touch data/feature_selector.py

# Run feature selection
python -c "
from data.feature_selector import FeatureSelector
selector = FeatureSelector()
selected = selector.select_by_correlation(df, threshold=0.8)
print(f'Selected {len(selected)} features')
"
```

### Phase 3: Model Variants
```bash
# Create variant models
mkdir -p models/variants
touch models/variants/simplex_lstm.py
touch models/variants/efficient_hybrid.py
touch models/variants/task_ensemble.py

# Train and compare
for model in simplex_lstm efficient_hybrid task_ensemble; do
    python scripts/train_model.py \
        --model $model \
        --output results/comparison_$model
done
```

### Phase 4: Frontend Setup
```bash
# Create React app
npx create-react-app frontend --template typescript
cd frontend

# Install dependencies
npm install react-router-dom recharts zustand react-query axios date-fns tailwindcss

# Start development server
npm start  # Runs on http://localhost:3000
```

---

## âœ… SUCCESS CRITERIA

âœ“ Phase 1 Complete:
- Index data integrated
- Feature selection reduces 60â†’35 features
- Data pipeline supports both individual symbols and indices

âœ“ Phase 2 Complete:
- All 3 model variants trained
- Performance comparison documented
- Best model selected based on: training time, accuracy, generalization

âœ“ Phase 3 Complete:
- React frontend running locally
- All pages (Dashboard, DataManager, Training, Backtest) functional
- Connected to backend APIs

âœ“ Phase 4 Complete:
- Advanced features implemented (curriculum, online learning, attention viz)
- Stress tests passing
- Ready for production deployment

